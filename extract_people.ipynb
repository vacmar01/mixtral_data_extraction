{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "caca1232",
      "metadata": {},
      "source": [
       "# Extract people's names from text using Mixtral 8x7b and returning it in JSON\n",
       "\n",
       "Recently, [mistral.ai](https://mistral.ai) - the (real) open source AI company from France - released their new open source \"mixture of experts (MoE)\" large language model, called \"Mixtral 8x7b\". To simplify, it's basically an ensemble of 8 7b models, where the inputs get dynamically routed to 2 of these 8 models.\n",
       "\n",
       "Also recently I got interested in using LLMs for something else than just chatbots. I stumbled upon a [repo](https://github.com/abacaj/openhermes-function-calling) from [Anton Bacaj](https://twitter.com/abacaj), where he get's a fine-tuned version of Mistral's 7b model to mimic the \"function calling\" API from OpenAI. \n",
       "\n",
       "This got me thinking about what I can use LLMs for. One idea was to extract structured data from unstructured text like podcast transcripts. \n",
       "\n",
       "This is my first take on it using Mixtral 8x7b through the [together.ai](https://together.ai) API. "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 15,
      "id": "65f96682",
      "metadata": {},
      "outputs": [],
      "source": [
       "from tqdm import tqdm\n",
       "from time import sleep\n",
       "import json\n",
       "import os\n",
       "from pydantic import BaseModel\n",
       "from typing import List"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bf61bf80",
      "metadata": {},
      "outputs": [],
      "source": [
       "sessionKey = os.environ['TOGETHER_SESSION_KEY']\n",
       "auth = os.environ['TOGETHER_AUTH']"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "568c9b13",
      "metadata": {},
      "source": [
       "This is the function that calls th model through [together.ai](https://together.ai/)'s API with the prompt and returns the response as JSON. \n",
       "\n",
       "I bet I could optimize the whole idea further by tuning the `temperature` and other parameters, but it works for now. "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 9,
      "id": "82d9a2ee",
      "metadata": {},
      "outputs": [],
      "source": [
       "def query_mistral(prompt):\n",
       "    import requests\n",
       "    endpoint = 'https://api.together.xyz/inference'\n",
       "    res = requests.post(endpoint, json={\n",
       "        \"model\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
       "        \"max_tokens\": 512,\n",
       "        \"prompt\": f\"[INST] {prompt} [/INST]\",\n",
       "        \"request_type\": \"language-model-inference\",\n",
       "        \"temperature\": 0.7,\n",
       "        \"top_p\": 0.7,\n",
       "        \"top_k\": 50,\n",
       "        \"repetition_penalty\": 1,\n",
       "        \"stop\": [\n",
       "            \"[/INST]\",\n",
       "            \"</s>\"\n",
       "        ],\n",
       "        \"negative_prompt\": \"\",\n",
       "        \"sessionKey\": sessionKey\n",
       "    }, headers={\n",
       "        \"Authorization\": f\"Bearer {auth}\",\n",
       "    })\n",
       "    return res.json()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 10,
      "id": "23c8895f",
      "metadata": {},
      "outputs": [],
      "source": [
       "with open(\"transcript_housel_perell.txt\", \"r\") as f:\n",
       "    transcript = f.read()"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a457c5ba",
      "metadata": {},
      "source": [
       "I want to use `pydantic` to validate the returned JSON. That's why I implement a simple `pydantic` class here to validate the returned JSON against. \n",
       "\n",
       "I know that you can serialize the json schema from a pydantic model directly and put it in the LLM prompt, but it actually didn't work so well for me. I think I have to look further into it. "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c49e8cf6",
      "metadata": {},
      "outputs": [],
      "source": [
       "class Person(BaseModel):\n",
       "    name: str\n",
       "\n",
       "class People(BaseModel):\n",
       "    names: List[Person]"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a3ccd57e",
      "metadata": {},
      "source": [
       "Below is the main code block. I loop over the text file in blocks of 16384 characters and extract the peoples names as JSON. \n",
       "\n",
       "Then I validate them against my `People` Model from above and if it's valid I will put it in my `result` list. \n",
       "\n",
       "There are clever things you could do to handle invalid json, like calling the LLM again or asking the LLM to turn the invalid JSON string into valid JSON, but again, it works for now.\n",
       "\n",
       "I also track the error rate for non-valid JSON here. But using Mixtral I never got non-valid JSON. It may only return more than just the JSON string, but that's easily fixed with the `.split()` call."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1793cbb3",
      "metadata": {},
      "outputs": [],
      "source": [
       "def get_prompt(text):\n",
       "    return f\"\"\"Given the following text, identify all the people's names mentioned and return them in a valid JSON format. \n",
       "\n",
       "    Text: '{text}' \n",
       "\n",
       "    Please extract the names and format them in JSON like this: \n",
       "\n",
       "    {{\"names\": [{{\"name\": \"Name1\"}}, {{\"name\": \"Name2\"}}, ...]}}.\n",
       "\n",
       "    Answer only with the json string, nothing else. This is very important!\n",
       "    \n",
       "    \"\"\""
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b833060a",
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "100%|██████████| 9/9 [00:26<00:00,  2.95s/it]"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Error rate: 0.0\n"
        ]
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "\n"
        ]
       }
      ],
      "source": [
       "result = []\n",
       "error = 0\n",
       "block_size = 16384\n",
       "for i in tqdm(range(0, len(transcript), block_size)):\n",
       "    prompt = get_prompt(transcript[i:i+block_size])\n",
       "\n",
       "    # get the output text and split it at the first double newline to get only the returned json string\n",
       "    outp = query_mistral(prompt)[\"output\"][\"choices\"][0][\"text\"].split(\"\\n\\n\")[0]\n",
       "\n",
       "    # validate the returned json string and if it's valid then append it to the result list\n",
       "    try:\n",
       "        People.model_validate_json(outp)\n",
       "        result.append(json.loads(outp))\n",
       "    except:\n",
       "        print(\"Invalid json\")\n",
       "        print(outp)\n",
       "        error = error + 1 \n",
       "    sleep(1) # to avoid rate limiting\n",
       "\n",
       "print(f\"Error rate: {error/len(result)}\")\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6be690a5",
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "[{'name': 'People'},\n",
          " {'name': 'you'},\n",
          " {'name': 'Michael Lewis'},\n",
          " {'name': 'Bethany McLean'},\n",
          " {'name': 'Joe Weisenthal'},\n",
          " {'name': 'Motley Fool'},\n",
          " {'name': 'The Molly Fool'},\n",
          " {'name': 'ting'},\n",
          " {'name': 'Marshall McLuhan'},\n",
          " {'name': 'Bill Clinton'},\n",
          " {'name': 'Keith Rabois'},\n",
          " {'name': 'Marc Andreessen'},\n",
          " {'name': 'Frederick Lewis Allen'},\n",
          " {'name': 'Winston Churchill'},\n",
          " {'name': 'John Maynard Keynes'},\n",
          " {'name': 'David McCullough'},\n",
          " {'name': 'LeBron James'},\n",
          " {'name': 'Barry Ritholtz'},\n",
          " {'name': 'Mark Twain'},\n",
          " {'name': 'Bill Bonner'},\n",
          " {'name': 'Felix Salmon'},\n",
          " {'name': 'Robert Curson'},\n",
          " {'name': 'ny lawyer'},\n",
          " {'name': 'Steve Jobs'},\n",
          " {'name': 'Warren Buffett'},\n",
          " {'name': 'Howard Marks'},\n",
          " {'name': 'Kafka'},\n",
          " {'name': 'Tom Stoppard'},\n",
          " {'name': 'Ken Burns'},\n",
          " {'name': 'Rick Burns'},\n",
          " {'name': 'Bezos'},\n",
          " {'name': 'Will'},\n",
          " {'name': 'Stephen Pressfield'},\n",
          " {'name': \"Patrick O'Shaughnessy\"},\n",
          " {'name': 'Tim Ferriss'},\n",
          " {'name': 'Charlie Munger'},\n",
          " {'name': 'Nassim Taleb'},\n",
          " {'name': 'Marcus Aurelius'},\n",
          " {'name': 'Aaron Haspel'},\n",
          " {'name': \"Beto O'Rourke\"},\n",
          " {'name': 'Kevin Kelly'},\n",
          " {'name': 'Larry King'},\n",
          " {'name': 'Bill Bryson'},\n",
          " {'name': 'Lyndon Johnson'},\n",
          " {'name': 'Robert Caro'},\n",
          " {'name': 'Gary Provost'},\n",
          " {'name': 'Morgan'},\n",
          " {'name': 'Jerry'},\n",
          " {'name': 'Cameron Diaz'},\n",
          " {'name': 'Mike Moritz'},\n",
          " {'name': 'Charlie Rose'}]"
         ]
        },
        "execution_count": 20,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "# flatten result\n",
       "flat_result = [name for r in result for name in r[\"names\"]]\n",
       "\n",
       "# deduplicate the result\n",
       "seen = set()\n",
       "deduplicated_data = [f  for f in flat_result if f['name'] not in seen and not seen.add(f['name'])]\n",
       "deduplicated_data"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }